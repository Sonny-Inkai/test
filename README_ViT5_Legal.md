# ViT5 Vietnamese Legal Joint Entity and Relation Extraction

Há»‡ thá»‘ng trÃ­ch xuáº¥t thá»±c thá»ƒ vÃ  quan há»‡ Ä‘á»“ng thá»i (Joint Entity and Relation Extraction) cho vÄƒn báº£n luáº­t Viá»‡t Nam sá»­ dá»¥ng mÃ´ hÃ¬nh ViT5.

## ğŸš€ TÃ­nh nÄƒng chÃ­nh

- **Joint Extraction**: TrÃ­ch xuáº¥t thá»±c thá»ƒ vÃ  quan há»‡ trong má»™t láº§n xá»­ lÃ½
- **Domain-specific**: Tá»‘i Æ°u cho vÄƒn báº£n luáº­t Viá»‡t Nam
- **ViT5-based**: Sá»­ dá»¥ng ViT5 (Vietnamese T5) thay vÃ¬ BART nhÆ° REBEL gá»‘c
- **Special Tokens**: Há»— trá»£ cÃ¡c loáº¡i thá»±c thá»ƒ vÃ  quan há»‡ Ä‘áº·c trung cho luáº­t phÃ¡p
- **End-to-end**: KhÃ´ng cáº§n pipeline phá»©c táº¡p

## ğŸ“‹ Cáº¥u trÃºc Special Tokens

### Entity Types:
- `<ORGANIZATION>`: Tá»• chá»©c, cÆ¡ quan (Bá»™ TÃ i chÃ­nh, á»¦y ban nhÃ¢n dÃ¢n...)
- `<LOCATION>`: Äá»‹a Ä‘iá»ƒm (Viá»‡t Nam, HÃ  Ná»™i...)
- `<DATE/TIME>`: Thá»i gian (01/01/2021, nÄƒm 2025...)
- `<LEGAL_PROVISION>`: Äiá»u khoáº£n phÃ¡p luáº­t (Äiá»u 5, Luáº­t Doanh nghiá»‡p 2020...)

### Relation Types:
- `<Relates_To>`: Quan há»‡ liÃªn quan chung
- `<Effective_From>`: CÃ³ hiá»‡u lá»±c tá»«
- `<Applicable_In>`: Ãp dá»¥ng táº¡i
- `<Amended_By>`: ÄÆ°á»£c sá»­a Ä‘á»•i bá»Ÿi

## ğŸ“Š Format dá»¯ liá»‡u

### Input Format:
```json
{
    "legal_1": {
        "title": "Äiá»u 2 01/2014/NQLT/CP-UBTÆ¯MTTQVN",
        "input_text": "Äiá»u 2 01/2014/NQLT/CP-UBTÆ¯MTTQVN hÆ°á»›ng dáº«n phá»‘i há»£p thá»±c hiá»‡n má»™t sá»‘ quy Ä‘á»‹nh cá»§a phÃ¡p luáº­t vá» hÃ²a giáº£i á»Ÿ cÆ¡ sá»Ÿ...",
        "extracted_relations": "<LEGAL_PROVISION> Äiá»u 2 01/2014/NQLT/CP-UBTÆ¯MTTQVN <ORGANIZATION> Máº·t tráº­n Tá»• quá»‘c Viá»‡t Nam <Relates_To>"
    }
}
```

### Output Format:
```
<LEGAL_PROVISION> Äiá»u 5 Nghá»‹ Ä‘á»‹nh 15/2020/NÄ-CP <ORGANIZATION> á»¦y ban nhÃ¢n dÃ¢n <Relates_To> <LEGAL_PROVISION> Luáº­t Doanh nghiá»‡p 2020 <DATE/TIME> 01/01/2021 <Effective_From>
```

## ğŸ› ï¸ CÃ i Ä‘áº·t

### 1. CÃ i Ä‘áº·t dependencies:
```bash
pip install -r requirements_vit5.txt
```

### 2. Chuáº©n bá»‹ dá»¯ liá»‡u:
- Äáº·t file `dataset.json` trong thÆ° má»¥c `/kaggle/input/vietnamese-legal-finetune-dataset/`
- Hoáº·c sá»­a Ä‘Æ°á»ng dáº«n trong `train_vit5_legal.py`

## ğŸƒ Cháº¡y Training

### 1. Training cÆ¡ báº£n:
```bash
python train_vit5_legal.py
```

### 2. Training vá»›i custom config:
Sá»­a `config` trong file `train_vit5_legal.py`:
```python
config = {
    'data_path': "/path/to/your/data",
    'model_name': "VietAI/vit5-base",  # hoáº·c "VietAI/vit5-large"
    'batch_size': 4,
    'learning_rate': 3e-4,
    'max_epochs': 10,
    'max_steps': 10000,
    'gradient_clip_val': 1.0,
    'accumulate_grad_batches': 4,
    'precision': 16  # Mixed precision Ä‘á»ƒ tiáº¿t kiá»‡m GPU
}
```

## ğŸ§ª Testing Model

### 1. Test vá»›i checkpoint:
```bash
python test_vit5_legal.py --model_path checkpoints/vit5-legal-epoch=05-val_loss=0.1234.ckpt
```

### 2. Test vá»›i data file:
```bash
python test_vit5_legal.py --model_path checkpoints/best_model/ --test_data test_data.json
```

### 3. Test vá»›i custom parameters:
```bash
python test_vit5_legal.py \
    --model_path checkpoints/best_model/ \
    --max_length 512 \
    --num_beams 5 \
    --test_data my_test_data.json
```

## ğŸ“ˆ Monitoring Training

### Training sáº½ hiá»ƒn thá»‹:
- **Loss theo epoch**: Train loss vÃ  validation loss
- **Sample generation**: Sau má»—i epoch sáº½ generate sample Ä‘á»ƒ kiá»ƒm tra
- **Model checkpoints**: Tá»± Ä‘á»™ng save best models trong `checkpoints/`
- **Early stopping**: Dá»«ng sá»›m náº¿u validation loss khÃ´ng cáº£i thiá»‡n

### VÃ­ dá»¥ output:
```
================================================================================
EPOCH 2 - SAMPLE GENERATION:
Input: extract relations: Äiá»u 5 Nghá»‹ Ä‘á»‹nh 15/2020/NÄ-CP quy Ä‘á»‹nh vá» tá»• chá»©c vÃ  hoáº¡t Ä‘á»™ng cá»§a á»¦y ban nhÃ¢n dÃ¢n xÃ£, phÆ°á»ng, thá»‹ tráº¥n. á»¦y ban nhÃ¢n dÃ¢n cÃ³ trÃ¡ch nhiá»‡m thá»±c hiá»‡n cÃ¡c nhiá»‡m vá»¥ Ä‘Æ°á»£c giao.
Generated: <LEGAL_PROVISION> Äiá»u 5 Nghá»‹ Ä‘á»‹nh 15/2020/NÄ-CP <ORGANIZATION> á»¦y ban nhÃ¢n dÃ¢n <Relates_To>
================================================================================
```

## âš™ï¸ Configuration

### GPU Settings:
- **T4x2 Kaggle**: Tá»± Ä‘á»™ng detect vÃ  sá»­ dá»¥ng 2 GPUs
- **Single GPU**: devices=1
- **CPU**: accelerator='cpu'

### Memory Optimization:
- **Mixed precision**: precision=16
- **Gradient accumulation**: accumulate_grad_batches=4
- **Batch size**: Äiá»u chá»‰nh theo GPU memory

### Model Variants:
```python
# Base model (nhanh hÆ¡n)
model_name = "VietAI/vit5-base"

# Large model (chÃ­nh xÃ¡c hÆ¡n)
model_name = "VietAI/vit5-large"
```

## ğŸ”§ Troubleshooting

### 1. Lá»—i GPU:
```python
# Fix cho PyTorch Lightning má»›i
trainer = pl.Trainer(
    accelerator='gpu',  # thay vÃ¬ gpus=2
    devices=2           # thay vÃ¬ gpus=2
)
```

### 2. Lá»—i AdamW:
```python
# Sá»­ dá»¥ng torch.optim thay vÃ¬ transformers
from torch.optim import AdamW
# thay vÃ¬ from transformers import AdamW
```

### 3. Memory issues:
```python
# Giáº£m batch size
batch_size = 2

# TÄƒng gradient accumulation
accumulate_grad_batches = 8

# Giáº£m sequence length
max_source_length = 256
max_target_length = 128
```

### 4. Slow training:
```python
# Giáº£m num_workers náº¿u CPU bottleneck
num_workers = 0

# Báº­t pin_memory
pin_memory = True

# Sá»­ dá»¥ng mixed precision
precision = 16
```

## ğŸ“Š Performance Tips

### 1. **Hyperparameter tuning**:
```python
learning_rate = 3e-4      # Báº¯t Ä‘áº§u vá»›i giÃ¡ trá»‹ nÃ y
warmup_steps = 1000       # 10% cá»§a total steps
weight_decay = 0.01       # Regularization
```

### 2. **Data preprocessing**:
- Normalize text trÆ°á»›c khi train
- Check quality cá»§a extracted_relations
- Balance data náº¿u cáº§n thiáº¿t

### 3. **Evaluation**:
- Monitor cáº£ train vÃ  validation loss
- Check sample generation quality
- Evaluate trÃªn test set riÃªng

## ğŸ“ File Structure

```
.
â”œâ”€â”€ train_vit5_legal.py       # Script training chÃ­nh
â”œâ”€â”€ test_vit5_legal.py        # Script testing
â”œâ”€â”€ requirements_vit5.txt     # Dependencies
â”œâ”€â”€ dataset.json              # Sample data
â”œâ”€â”€ README_ViT5_Legal.md      # Documentation nÃ y
â”œâ”€â”€ checkpoints/              # Model checkpoints (tá»± táº¡o)
â”‚   â”œâ”€â”€ vit5-legal-epoch-xx-val_loss-x.xxxx.ckpt
â”‚   â””â”€â”€ last.ckpt
â”œâ”€â”€ train_data.json          # Training split (tá»± táº¡o)
â”œâ”€â”€ val_data.json            # Validation split (tá»± táº¡o)
â””â”€â”€ test_data.json           # Test split (tá»± táº¡o)
```

## ğŸ¯ VÃ­ dá»¥ sá»­ dá»¥ng

### Training:
```python
# Chá»‰ cáº§n cháº¡y
python train_vit5_legal.py
```

### Testing:
```python
# Load model vÃ  test
from test_vit5_legal import ViT5LegalTester

tester = ViT5LegalTester("checkpoints/best_model/")
result = tester.extract_relations("Äiá»u 5 Luáº­t Doanh nghiá»‡p 2020 cÃ³ hiá»‡u lá»±c tá»« 01/01/2021")
print(result)
```

## ğŸ¤ ÄÃ³ng gÃ³p

1. Fork repository
2. Táº¡o feature branch
3. Commit changes
4. Push vÃ  táº¡o Pull Request

## ğŸ“„ License

MIT License - Xem file LICENSE Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t.

## ğŸ™ Acknowledgments

- **REBEL**: Inspiration tá»« paper "REBEL: Relation Extraction By End-to-end Language generation"
- **ViT5**: Vietnamese T5 model tá»« VietAI
- **PyTorch Lightning**: Framework training
- **Transformers**: Hugging Face library 